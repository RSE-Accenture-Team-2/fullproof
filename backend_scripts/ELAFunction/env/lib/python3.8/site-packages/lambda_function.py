from bs4 import BeautifulSoup
import requests
import json
import traceback


def lambda_handler(event, context):
    try:
        headers = {
            'authority': 'scrapeme.live',
            'dnt': '1',
            'upgrade-insecure-requests': '1',
            'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.61 Safari/537.36',
            'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9',
            'sec-fetch-site': 'none',
            'sec-fetch-mode': 'navigate',
            'sec-fetch-user': '?1',
            'sec-fetch-dest': 'document',
            'accept-language': 'en-GB,en-US;q=0.9,en;q=0.8'
        }

        proxies = {
            "https": "134.125.152.121:3128",
            "http": "34.125.152.121:3128"
        }
        url = event["body"]["url"]
        data = {'url': url}
        base_url = 'http://fotoforensics.com'
        response = requests.post(
            f'{ base_url }/upload-url.php', data=data, proxies=proxies, timeout=15, headers=headers)

        print(response.status_code)
        soup = BeautifulSoup(response.text, 'html.parser')
        img_endpoint = soup.find(id="MainImg")
        img_endpoint = img_endpoint.attrs["src"]
        img_endpoint = str(img_endpoint).split("&")[0] + "&fmt=ela"
        dns = base_url + img_endpoint
        return {
            "statusCode": 200,
            "body": json.dumps({'ELAlink': dns})
        }
    except Exception as e:
        print()
        return {
            "statusCode": 500,
            "body": json.dumps(traceback.format_exc())
        }


if __name__ == "__main__":
    event = {
        "body": {'url': 'https://i.insider.com/5ea8734ca34b3c340e3bd55a?width=1800&format=jpeg&auto=webp'}
    }
    context = None
    result = lambda_handler(event, context)
    print(result)
